name: Advanced Bug Bounty Scanner

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
  schedule:
    - cron: '13 1 * * *'
    - cron: '47 5 * * *'
    - cron: '29 9 * * *'
    - cron: '53 14 * * *'
    - cron: '11 18 * * *'

jobs:
  vulnerability-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install scanning dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y git python3 python3-pip nikto nmap unzip wget golang jq curl
          echo "GOPATH=$HOME/go" >> $GITHUB_ENV
          echo "PATH=$PATH:/usr/local/go/bin:$HOME/go/bin" >> $GITHUB_ENV
          go install github.com/tomnomnom/assetfinder@latest
          go install github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          go install github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
          sudo mv ~/go/bin/{assetfinder,nuclei,httpx,subfinder} /usr/local/bin/
          curl -s https://api.github.com/repos/findomain/findomain/releases/latest | grep "browser_download_url.*findomain-linux" | cut -d '"' -f 4 | xargs curl -LO
          chmod +x findomain-linux
          sudo mv findomain-linux /usr/local/bin/findomain
          nuclei -update-templates -silent

      - name: Verify domains file exists
        run: |
          if [ ! -f ".github/workflows/domains.txt" ]; then
            echo "ERROR: domains.txt file not found!"
            exit 1
          fi
          echo "Target domains:"
          cat .github/workflows/domains.txt

      - name: Detect subdomains
        id: subdomain-detection
        run: |
          set -e
          mkdir -p subdomain_output old_subdomains
          new_subdomains_detected=false
          while IFS= read -r domain; do
            domain=$(echo "$domain" | tr -d '\r\n')
            echo "üõ†Ô∏è Processing $domain"
            output_file="subdomain_output/${domain//./_}_subdomains.txt"
            assetfinder --subs-only $domain | httpx -silent > "$output_file" || true
            subfinder -d "$domain" -silent >> "$output_file" || true
            findomain -t "$domain" --quiet >> "$output_file" || true
            sort -u "$output_file" -o "$output_file"
            sed -i '/^$/d' "$output_file"
            if [ -s "$output_file" ]; then
              echo "‚úÖ Found $(wc -l < "$output_file") subdomains"
              if [ -f "old_subdomains/${domain//./_}_old_subdomains.txt" ]; then
                if ! diff -q "$output_file" "old_subdomains/${domain//./_}_old_subdomains.txt"; then
                  new_subdomains_detected=true
                  echo "üî• New subdomains found!"
                fi
              else
                new_subdomains_detected=true
                echo "üåü First run - all subdomains are new"
              fi
              cp "$output_file" "old_subdomains/${domain//./_}_old_subdomains.txt"
            else
              echo "‚ùå No subdomains found"
              touch "old_subdomains/${domain//./_}_old_subdomains.txt"
            fi
          done < .github/workflows/domains.txt
          echo "new_subdomains_detected=$new_subdomains_detected" >> $GITHUB_ENV

      - name: Prepare ZAP plan
        run: |
          mkdir -p .github/zap
          if [ ! -f ".github/zap/plan.yml" ]; then
            printf "%s\n" \
              "plans:" \
              "  - name: \"Default Scan\"" \
              "    parameters:" \
              "      target: \"https://TARGET_DOMAIN\"" \
              "      rules:" \
              "        - \"scan_rules/automatic\"" \
              "    context:" \
              "      name: \"Default Context\"" \
              "      includePaths:" \
              "        - \"https://TARGET_DOMAIN/.*\"" \
              > .github/zap/plan.yml
          fi
          echo "ZAP plan file ready."

      - name: Run ZAP Scan (Dynamic Target)
        if: env.new_subdomains_detected == 'true'
        run: |
          while IFS= read -r domain; do
            domain=$(echo "$domain" | tr -d '\r\n')
            echo "üîç Running ZAP scan for $domain"
            sed -i "s|TARGET_DOMAIN|$domain|g" .github/zap/plan.yml
            docker run --rm -v $(pwd):/zap/wrk -t ghcr.io/zaproxy/action-full-scan:latest -c .github/zap/plan.yml || echo "ZAP scan completed (some errors may be non-critical)"
            sed -i "s|$domain|TARGET_DOMAIN|g" .github/zap/plan.yml
          done < .github/workflows/domains.txt

      - name: Run Nikto Scan
        if: env.new_subdomains_detected == 'true'
        run: |
          mkdir -p nikto-reports
          while IFS= read -r domain; do
            domain=$(echo "$domain" | tr -d '\r\n')
            echo "üîç Nikto scanning $domain"
            nikto -h "https://$domain" -Format htm -output "nikto-reports/nikto-${domain//./_}.html" -nointeractive || echo "Nikto scan completed (ignoring update errors)"
          done < .github/workflows/domains.txt

      - name: Run Nuclei Scan
        if: env.new_subdomains_detected == 'true'
        run: |
          mkdir -p nuclei-reports
          while IFS= read -r domain; do
            domain=$(echo "$domain" | tr -d '\r\n')
            echo "üí£ Nuclei scanning $domain"
            nuclei -u "https://$domain" -severity critical,high,medium,low,info -j -o "nuclei-reports/nuclei-${domain//./_}.json" -timeout 30 -silent || echo "Nuclei scan completed (some errors may be non-critical)"
          done < .github/workflows/domains.txt

      - name: Generate Summary CSV and HTML Dashboard
        if: env.new_subdomains_detected == 'true'
        run: |
          mkdir -p summaries
          echo "domain,severity,name,url" > summaries/nuclei-findings.csv
          for file in nuclei-reports/*.json; do
            jq -r '[.host, .info.severity, .info.name, .matched-at] | @csv' "$file" >> summaries/nuclei-findings.csv
          done
          echo "<html><body><h1>Scan Summary</h1><table border='1'><tr><th>Domain</th><th>Severity</th><th>Name</th><th>URL</th></tr>" > summaries/nuclei-summary.html
          tail -n +2 summaries/nuclei-findings.csv | while IFS=',' read -r domain severity name url; do
            echo "<tr><td>$domain</td><td>$severity</td><td>$name</td><td><a href='$url'>$url</a></td></tr>" >> summaries/nuclei-summary.html
          done
          echo "</table></body></html>" >> summaries/nuclei-summary.html

      - name: Upload Summary Reports
        uses: actions/upload-artifact@v4
        if: env.new_subdomains_detected == 'true'
        with:
          name: summary-files-${{ github.run_id }}
          path: |
            summaries/*.csv
            summaries/*.html

      - name: Create GitHub Issues for Critical/High
        if: env.new_subdomains_detected == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          for file in nuclei-reports/*.json; do
            jq -c 'select(.info.severity == "critical" or .info.severity == "high")' "$file" | while read -r vuln; do
              title=$(echo "$vuln" | jq -r '.info.name')
              url=$(echo "$vuln" | jq -r '.matched-at')
              severity=$(echo "$vuln" | jq -r '.info.severity')
              body="**Severity**: $severity%0A**URL**: $url%0A**Template**: $(echo "$vuln" | jq -r '.template')"
              gh issue create --title "$title [$severity]" --body "$body" --label "bug,bounty,auto-created"
            done
          done
