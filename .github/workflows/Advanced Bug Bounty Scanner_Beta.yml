name: Advanced Bug Bounty Scanner

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      domains:
        description: 'Comma-separated list of domains to scan (overrides domains.txt)'
        required: false
  schedule:
    - cron: '13 1 * * *'
    - cron: '47 5 * * *'
    - cron: '29 9 * * *'
    - cron: '53 14 * * *'
    - cron: '11 18 * * *'

jobs:
  vulnerability-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 120  # Default timeout, can be overridden with env later

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Initialize environment variables
        id: set-env
        run: |
          echo "SCAN_TIMEOUT=120" >> $GITHUB_ENV
          echo "NUCLEI_TIMEOUT=60" >> $GITHUB_ENV
          echo "ZAP_TIMEOUT=1800" >> $GITHUB_ENV
          echo "MAX_CONCURRENT_SCANS=3" >> $GITHUB_ENV

      - name: Setup domains input
        id: domains-input
        run: |
          if [ -n "${{ github.event.inputs.domains }}" ]; then
            echo "${{ github.event.inputs.domains }}" | tr ',' '\n' > .github/workflows/domains.txt
            echo "Using input domains: ${{ github.event.inputs.domains }}"
          fi

      - name: Install scanning dependencies
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y --no-install-recommends \
            git python3 python3-pip nikto nmap unzip wget golang jq curl docker.io
          
          # Configure Go environment
          echo "GOPATH=$HOME/go" >> $GITHUB_ENV
          echo "PATH=$PATH:/usr/local/go/bin:$HOME/go/bin" >> $GITHUB_ENV
          
          # Install Go tools
          go install github.com/tomnomnom/assetfinder@latest
          go install github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          go install github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
          go install github.com/projectdiscovery/naabu/v2/cmd/naabu@latest
          sudo mv ~/go/bin/{assetfinder,nuclei,httpx,subfinder,naabu} /usr/local/bin/
          
          # Install Findomain
          curl -s https://api.github.com/repos/findomain/findomain/releases/latest \
            | grep "browser_download_url.*linux.zip" \
            | cut -d '"' -f 4 \
            | wget -q -i -
          unzip -q findomain-linux.zip
          chmod +x findomain
          sudo mv findomain /usr/local/bin/findomain
          
          # Update templates
          nuclei -update-templates -silent
          
          # Install ZAP
          docker pull ghcr.io/zaproxy/action-full-scan:latest

      - name: Verify domains file exists
        id: verify-domains
        run: |
          if [ ! -f ".github/workflows/domains.txt" ]; then
            echo "ERROR: domains.txt file not found!"
            exit 1
          fi
          
          # Clean and validate domains
          sed -i '/^[[:space:]]*$/d; /^#/d' .github/workflows/domains.txt
          if [ ! -s ".github/workflows/domains.txt" ]; then
            echo "ERROR: domains.txt is empty after cleaning!"
            exit 1
          fi
          
          echo "Target domains:"
          cat .github/workflows/domains.txt
          echo "DOMAINS_COUNT=$(wc -l < .github/workflows/domains.txt | tr -d ' ')" >> $GITHUB_ENV

      - name: Detect subdomains (with multi-domain diffing)
        id: subdomain-detection
        timeout-minutes: ${{ env.SCAN_TIMEOUT }}
        run: |
          set -eo pipefail
          mkdir -p subdomain_output old_subdomains
          new_subdomains_found=()
          changed_domains=()
          
          while IFS= read -r domain || [ -n "$domain" ]; do
            domain=$(echo "$domain" | tr -d '\r\n' | xargs)
            [ -z "$domain" ] && continue
            
            echo "ðŸ”Ž Processing $domain"
            output_file="subdomain_output/${domain//./_}_subdomains.txt"
            
            # Run subdomain discovery tools in parallel
            {
              assetfinder --subs-only "$domain" | httpx -silent || true
              subfinder -d "$domain" -silent || true
              findomain -t "$domain" --quiet || true
            } | sort -u | tee "$output_file"
            
            sed -i '/^$/d' "$output_file"
            
            # Check for new subdomains
            old_file="old_subdomains/${domain//./_}_old_subdomains.txt"
            if [ ! -f "$old_file" ]; then
              echo "ðŸŒŸ First scan for $domain â€” storing results"
              cp "$output_file" "$old_file"
              new_subdomains_found+=("$domain")
              changed_domains+=("$domain")
            else
              if ! diff -q "$output_file" "$old_file" > /dev/null; then
                echo "ðŸ”¥ New subdomains detected for $domain!"
                new_subdomains=$(comm -13 <(sort "$old_file") <(sort "$output_file") | wc -l)
                echo "Found $new_subdomains new subdomains"
                cp "$output_file" "$old_file"
                changed_domains+=("$domain")
              else
                echo "âœ… No new subdomains for $domain"
              fi
            fi
          done < .github/workflows/domains.txt

          # Set environment variables
          echo "NEW_DOMAINS=${new_subdomains_found[*]}" >> $GITHUB_ENV
          echo "CHANGED_DOMAINS=${changed_domains[*]}" >> $GITHUB_ENV
          
          if [ "${#changed_domains[@]}" -gt 0 ]; then
            echo "new_subdomains_detected=true" >> $GITHUB_ENV
          else
            echo "new_subdomains_detected=false" >> $GITHUB_ENV
          fi

      - name: Prepare ZAP plan
        run: |
          mkdir -p .github/zap
          if [ ! -f ".github/zap/plan.yml" ]; then
            cat << EOF > .github/zap/plan.yml
plans:
  - name: "Default Scan"
    parameters:
      target: "https://TARGET_DOMAIN"
      rules:
        - "scan_rules/automatic"
    context:
      name: "Default Context"
      includePaths:
        - "https://TARGET_DOMAIN/.*"
EOF
          fi

      - name: Run port scans with Naabu
        if: env.new_subdomains_detected == 'true'
        timeout-minutes: ${{ env.SCAN_TIMEOUT }}
        run: |
          mkdir -p port-scans
          for domain in $CHANGED_DOMAINS; do
            echo "ðŸ” Scanning ports for $domain"
            naabu -host "$domain" -silent -json -o "port-scans/naabu-${domain//./_}.json" || echo "Naabu scan completed"
          done

      - name: Run ZAP Scan (Dynamic Targets)
        if: env.new_subdomains_detected == 'true'
        timeout-minutes: ${{ env.ZAP_TIMEOUT }}
        run: |
          for domain in $CHANGED_DOMAINS; do
            echo "ðŸ•·ï¸ Running ZAP scan for $domain"
            sed -i "s|TARGET_DOMAIN|$domain|g" .github/zap/plan.yml
            docker run --rm -v $(pwd):/zap/wrk -t ghcr.io/zaproxy/action-full-scan:latest \
              -c .github/zap/plan.yml -T ${{ env.ZAP_TIMEOUT }} || echo "ZAP scan completed"
            sed -i "s|$domain|TARGET_DOMAIN|g" .github/zap/plan.yml
          done

      - name: Run Nikto Scan
        if: env.new_subdomains_detected == 'true'
        timeout-minutes: ${{ env.SCAN_TIMEOUT }}
        run: |
          mkdir -p nikto-reports
          for domain in $CHANGED_DOMAINS; do
            echo "ðŸ”¬ Nikto scanning $domain"
            timeout 600 nikto -h "https://$domain" -Format htm -output "nikto-reports/nikto-${domain//./_}.html" -nointeractive || echo "Nikto done"
          done

      - name: Run Nuclei Scan
        if: env.new_subdomains_detected == 'true'
        timeout-minutes: ${{ env.NUCLEI_TIMEOUT }}
        run: |
          mkdir -p nuclei-reports
          # Run nuclei with parallel processing
          echo "$CHANGED_DOMAINS" | tr ' ' '\n' | xargs -P ${{ env.MAX_CONCURRENT_SCANS }} -I {} bash -c '
            domain={}
            echo "ðŸ’£ Nuclei scanning $domain"
            nuclei -u "https://$domain" -severity critical,high,medium,low -j \
              -o "nuclei-reports/nuclei-${domain//./_}.json" -timeout ${{ env.NUCLEI_TIMEOUT }} -silent \
              || echo "Nuclei scan completed for $domain"
          '

      - name: Generate Summary Reports
        if: env.new_subdomains_detected == 'true'
        timeout-minutes: ${{ env.SCAN_TIMEOUT }}
        run: |
          mkdir -p summaries
          
          # Create CSV report
          echo "domain,severity,name,url,template,description" > summaries/nuclei-findings.csv
          for file in nuclei-reports/*.json; do
            jq -r '[.host, .info.severity, .info.name, .matched, .template, .info.description? // ""] | @csv' "$file" >> summaries/nuclei-findings.csv
          done
          
          # Create HTML report
          cat << EOF > summaries/nuclei-summary.html
<html>
<head>
  <title>Vulnerability Scan Report</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 20px; }
    table { border-collapse: collapse; width: 100%; }
    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
    tr:nth-child(even) { background-color: #f2f2f2; }
    .critical { background-color: #ffcccc; }
    .high { background-color: #ffe6cc; }
    .medium { background-color: #ffffcc; }
    .low { background-color: #e6ffcc; }
  </style>
</head>
<body>
  <h1>Vulnerability Scan Summary</h1>
  <table>
    <tr><th>Domain</th><th>Severity</th><th>Name</th><th>URL</th><th>Description</th></tr>
EOF
          
          tail -n +2 summaries/nuclei-findings.csv | while IFS=',' read -r domain severity name url template description; do
            severity_class=$(echo "$severity" | tr '[:upper:]' '[:lower:]')
            echo "<tr class=\"$severity_class\"><td>$domain</td><td>$severity</td><td>$name</td><td><a href=\"$url\">$url</a></td><td>${description//\"/}</td></tr>" \
              >> summaries/nuclei-summary.html
          done
          
          echo "</table><p>Report generated on $(date)</p></body></html>" >> summaries/nuclei-summary.html
          
          # Create markdown summary
          echo "# Vulnerability Scan Report" > summaries/summary.md
          echo "Generated on $(date)" >> summaries/summary.md
          echo "## Summary by Severity" >> summaries/summary.md
          echo "| Severity | Count |" >> summaries/summary.md
          echo "|----------|-------|" >> summaries/summary.md
          tail -n +2 summaries/nuclei-findings.csv | cut -d',' -f2 | sort | uniq -c | awk '{print "| " $2 " | " $1 " |"}' >> summaries/summary.md

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        if: env.new_subdomains_detected == 'true'
        with:
          name: scan-results-${{ github.run_id }}
          path: |
            summaries/*
            nikto-reports/*
            nuclei-reports/*
            port-scans/*
            subdomain_output/*

      - name: Create GitHub Issues for Critical/High
        if: env.new_subdomains_detected == 'true'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        timeout-minutes: ${{ env.SCAN_TIMEOUT }}
        run: |
          for file in nuclei-reports/*.json; do
            jq -c 'select(.info.severity == "critical" or .info.severity == "high")' "$file" | while read -r vuln; do
              title=$(echo "$vuln" | jq -r '.info.name')
              url=$(echo "$vuln" | jq -r '.matched')
              severity=$(echo "$vuln" | jq -r '.info.severity')
              template=$(echo "$vuln" | jq -r '.template')
              description=$(echo "$vuln" | jq -r '.info.description? // ""')
              
              # Check if issue already exists
              existing_issue=$(gh issue list --search "in:title \"$title\" in:title \"$severity\"" --json number -q '.[0].number')
              
              if [ -z "$existing_issue" ]; then
                body=$(cat << EOF
**Severity**: $severity  
**URL**: $url  
**Template**: $template  
**Description**: $description  
**Domain**: $(basename "$file" | sed 's/nuclei-\(.*\)\.json/\1/' | tr '_' '.')
EOF
                )
                
                gh issue create --title "$title [$severity]" --body "$body" --label "bug,bounty,auto-created,$severity"
              else
                echo "Issue already exists: #$existing_issue"
              fi
            done
          done

      - name: Notify Slack of Critical/High Findings
        if: env.new_subdomains_detected == 'true'
        timeout-minutes: ${{ env.SCAN_TIMEOUT }}
        run: |
          critical_count=0
          high_count=0
          
          # Count findings
          for file in nuclei-reports/*.json; do
            crit=$(jq -c 'select(.info.severity == "critical")' "$file" | wc -l)
            high=$(jq -c 'select(.info.severity == "high")' "$file" | wc -l)
            critical_count=$((critical_count + crit))
            high_count=$((high_count + high))
          done
          
          # Prepare message
          if [ $critical_count -gt 0 ] || [ $high_count -gt 0 ]; then
            message="ðŸš¨ *Security Alert* ðŸš¨\n"
            message+="*Critical findings*: $critical_count\n"
            message+="*High findings*: $high_count\n"
            message+="*Scan details*: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            
            curl -X POST -H 'Content-type: application/json' \
              --data "{\"text\":\"$message\"}" \
              ${{ secrets.SLACK_WEBHOOK_URL }}
          else
            echo "No critical/high findings to report"
          fi

      - name: Clean up workspace
        run: |
          docker system prune -af
          sudo rm -rf /tmp/*
