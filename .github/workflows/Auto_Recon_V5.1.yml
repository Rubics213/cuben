name: Vulnerability Scanning & Subdomain Detection

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:  # Manual trigger
  schedule:
    # Randomizing cron schedule for effective scanning
    - cron: '17 3 * * 2'  # Example: Run at a random time, change weekly
    - cron: '42 14 * * 6' # Another random time for different days
    - cron: '33 21 * * 4' # Random evening scan

jobs:
  vulnerability-scan:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      # Install Sublist3r
      - name: Install Sublist3r dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y git python3 python3-pip
          git clone https://github.com/aboul3la/Sublist3r.git
          cd Sublist3r
          pip3 install -r requirements.txt

      # Use Sublist3r to detect subdomains
      - name: Detect subdomains
        run: |
          set -e
          mkdir -p subdomain_output old_subdomains
          new_subdomains_detected=false

          # Slow down the scan to avoid flagging
          delay_between_requests=5  # Introduce a 5-second delay
          while IFS= read -r domain; do
            echo "Finding subdomains for $domain"
            output_file="subdomain_output/${domain//https:\/\//}_subdomains.txt"

            # Use Python's requests module with a custom user-agent
            python3 -c "
import requests, time
url = f'https://api.sublist3r.com/?domain={domain}'
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
r = requests.get(url, headers=headers)
with open('$output_file', 'w') as f:
    f.write(r.text)
time.sleep($delay_between_requests)
"

            # Check for new subdomains
            if [ -f "$output_file" ]; then
              if [ -f "old_subdomains/${domain//https:\/\//}_old_subdomains.txt" ]; then
                if ! diff "$output_file" "old_subdomains/${domain//https:\/\//}_old_subdomains.txt"; then
                  echo "New subdomains detected for $domain"
                  new_subdomains_detected=true
                fi
              else
                echo "First run for $domain, no old subdomains to compare."
                new_subdomains_detected=true
              fi

              # Save current subdomains for the next run
              cp "$output_file" "old_subdomains/${domain//https:\/\//}_old_subdomains.txt"
            else
              echo "No subdomains found for $domain. Skipping comparison."
            fi
          done < .github/workflows/domains.txt

          # Set output variable for new subdomains detection
          echo "new_subdomains_detected=${new_subdomains_detected}" >> $GITHUB_ENV

      # Run OWASP ZAP Scan only if new subdomains were detected
      - name: Run OWASP ZAP Scan
        if: env.new_subdomains_detected == 'true'
        uses: zaproxy/action-baseline@v0.10.0
        with:
          target: 'https://linkedin.com'  # Replace with target domain
          rules_file_name: '.github/zap/rules.tsv'

      - name: Upload ZAP report
        if: env.new_subdomains_detected == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: zap-report
          path: owasp-zap-report.html

      # Install Nikto
      - name: Install Nikto
        run: sudo apt-get update && sudo apt-get install -y nikto

      # Run Nikto Scan only if new subdomains were detected
      - name: Run Nikto Scan
        if: env.new_subdomains_detected == 'true'
        run: |
          mkdir -p nikto-output
          nikto -h https://linkedin.com -output nikto-output/nikto_report.txt

      - name: Upload Nikto report
        if: env.new_subdomains_detected == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: nikto-report
          path: nikto-output/nikto_report.txt

      - name: Display Scan Summary
        run: |
          echo "OWASP ZAP and Nikto Scans Completed"
