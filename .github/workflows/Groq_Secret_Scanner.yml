name: Production JS Security Scanner

on:
  push:
    branches: [main, master]
    paths:
      - 'targets.txt'
  workflow_dispatch:
  schedule:
    - cron: '0 3 * * *'

permissions:
  contents: write
  actions: read

jobs:
  intelligent-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup Directories
        run: |
          mkdir -p reports tmp stats
          echo "‚úÖ Workspace ready"

      - name: Cache Tools
        id: cache-tools
        uses: actions/cache@v4
        with:
          path: ~/go/bin
          key: ${{ runner.os }}-tools-v5

      - name: Install Dependencies
        run: |
          echo "üì¶ Installing packages..."
          pip install --no-cache-dir groq aiohttp requests || pip install --break-system-packages groq aiohttp requests
          
          if [[ ! -f ~/go/bin/katana ]]; then
            go install github.com/projectdiscovery/katana/cmd/katana@latest
          fi
          
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
          echo "‚úÖ Ready"

      - name: Create Production Scanner
        run: |
          cat > production_js_scanner.py << 'PYTHON_SCRIPT'
          #!/usr/bin/env python3
          """
          Production-Grade JS Security Scanner with Intelligence
          Features: Deduplication, Smart filtering, Severity ranking, Actionable reports
          """
          
          import os
          import sys
          import json
          import asyncio
          import re
          import hashlib
          from typing import List, Dict, Optional, Set
          from urllib.parse import urlparse
          
          try:
              from groq import Groq
              GROQ_AVAILABLE = True
          except ImportError:
              GROQ_AVAILABLE = False
          
          # Initialize
          GROQ_API_KEY = os.getenv("GROQ_API_KEY")
          client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY and GROQ_AVAILABLE else None
          
          # Enhanced patterns with severity
          PATTERNS = {
              "private_key": {
                  "regex": r'-----BEGIN (RSA |EC |DSA |OPENSSH )?PRIVATE KEY-----',
                  "severity": "CRITICAL",
                  "risk": "Full system compromise"
              },
              "aws_key": {
                  "regex": r'(?i)(AKIA|ASIA)[A-Z0-9]{16}',
                  "severity": "CRITICAL",
                  "risk": "AWS account takeover"
              },
              "jwt_token": {
                  "regex": r'eyJ[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}',
                  "severity": "HIGH",
                  "risk": "Session hijacking"
              },
              "api_key": {
                  "regex": r'(?i)(api[_-]?key|apikey)\s*[:=]\s*["\']([a-zA-Z0-9_\-]{20,})["\']',
                  "severity": "HIGH",
                  "risk": "Unauthorized API access"
              },
              "github_token": {
                  "regex": r'gh[pousr]_[A-Za-z0-9_]{36,}',
                  "severity": "CRITICAL",
                  "risk": "Repository access"
              },
              "slack_token": {
                  "regex": r'xox[baprs]-[0-9]{10,13}-[0-9]{10,13}-[a-zA-Z0-9]{24,}',
                  "severity": "HIGH",
                  "risk": "Workspace compromise"
              },
              "secret": {
                  "regex": r'(?i)(secret|password)\s*[:=]\s*["\']([^"\']{12,})["\']',
                  "severity": "HIGH",
                  "risk": "Authentication bypass"
              },
              "database_url": {
                  "regex": r'(?i)(mongodb|mysql|postgres|redis)://[^\s\'"]+',
                  "severity": "CRITICAL",
                  "risk": "Database access"
              },
              "bearer_token": {
                  "regex": r'(?i)bearer\s+[a-zA-Z0-9_\-\.]{20,}',
                  "severity": "HIGH",
                  "risk": "Unauthorized access"
              }
          }
          
          # Smarter boilerplate detection
          BOILERPLATE_INDICATORS = [
              "example", "demo", "test", "placeholder", "sample", "your_",
              "insert_", "replace_", "enter_", "paste_", "add_your",
              "TODO", "FIXME", "xxx", "yyy", "zzz", "abc123",
              "config.example", "env.example", ".env.sample"
          ]
          
          # Library indicators (skip these JS files)
          LIBRARY_INDICATORS = [
              "jquery", "bootstrap", "react", "angular", "vue", "lodash",
              "moment", "axios", "webpack", "bundle", "vendor", "polyfill",
              "chunk", "framework", "cdn", "min.js", "analytics", "gtag"
          ]
          
          
          class JavaScriptAnalyzer:
              def __init__(self):
                  self.seen_hashes: Set[str] = set()
                  self.stats = {
                      "total_files": 0,
                      "skipped_duplicates": 0,
                      "skipped_libraries": 0,
                      "analyzed": 0,
                      "findings": 0
                  }
              
              def is_library(self, url: str) -> bool:
                  """Detect if JS is a library (skip it)"""
                  url_lower = url.lower()
                  return any(lib in url_lower for lib in LIBRARY_INDICATORS)
              
              def is_boilerplate(self, text: str) -> bool:
                  """Enhanced boilerplate detection"""
                  text_lower = text.lower()
                  
                  # Check for placeholder patterns
                  if any(bp in text_lower for bp in BOILERPLATE_INDICATORS):
                      return True
                  
                  # Check for repeated placeholder chars
                  if re.search(r'(x{5,}|y{5,}|z{5,}|\*{5,})', text_lower):
                      return True
                  
                  # Check for common example values
                  if re.search(r'(12345|abcde|qwerty)', text_lower):
                      return True
                  
                  return False
              
              def get_content_hash(self, content: str) -> str:
                  """Generate hash for deduplication"""
                  return hashlib.md5(content.encode()).hexdigest()
              
              def is_duplicate(self, content: str) -> bool:
                  """Check if we've seen this JS before"""
                  content_hash = self.get_content_hash(content)
                  if content_hash in self.seen_hashes:
                      return True
                  self.seen_hashes.add(content_hash)
                  return False
              
              def extract_context(self, content: str, match_pos: int, size: int = 150) -> str:
                  """Extract context with better formatting"""
                  start = max(0, match_pos - size)
                  end = min(len(content), match_pos + size)
                  context = content[start:end]
                  
                  # Clean up
                  context = re.sub(r'\s+', ' ', context)
                  return context.strip()
              
              def pattern_scan(self, content: str, url: str) -> List[Dict]:
                  """Enhanced pattern scanning with severity"""
                  findings = []
                  
                  for pattern_name, pattern_info in PATTERNS.items():
                      try:
                          matches = re.finditer(pattern_info["regex"], content)
                          for match in matches:
                              context = self.extract_context(content, match.start())
                              
                              if self.is_boilerplate(context):
                                  continue
                              
                              findings.append({
                                  "type": pattern_name,
                                  "severity": pattern_info["severity"],
                                  "risk": pattern_info["risk"],
                                  "url": url,
                                  "context": context[:250],
                                  "match": match.group(0)[:100],
                                  "line": content[:match.start()].count('\n') + 1,
                                  "confidence": "pattern_match",
                                  "recommendation": self.get_recommendation(pattern_name)
                              })
                      except Exception:
                          continue
                  
                  return findings
              
              def get_recommendation(self, vuln_type: str) -> str:
                  """Provide actionable recommendations"""
                  recommendations = {
                      "private_key": "URGENT: Rotate key immediately. Never commit keys to code.",
                      "aws_key": "URGENT: Deactivate key in AWS Console. Enable CloudTrail to check for unauthorized access.",
                      "api_key": "Rotate key immediately. Move to environment variables or secrets manager.",
                      "github_token": "Revoke token on GitHub. Check audit log for unauthorized access.",
                      "slack_token": "Revoke token in Slack workspace. Review channel access logs.",
                      "database_url": "URGENT: Rotate credentials. Restrict database access by IP.",
                      "jwt_token": "If valid, invalidate all sessions. Implement proper token storage.",
                      "secret": "Rotate credential immediately. Move to secure secrets manager.",
                      "bearer_token": "Invalidate token. Implement proper authentication flow."
                  }
                  return recommendations.get(vuln_type, "Review and rotate if necessary.")
              
              async def llm_analyze(self, content: str, url: str) -> Optional[Dict]:
                  """LLM deep analysis for subtle issues"""
                  if not client:
                      return None
                  
                  # Only analyze suspicious sections
                  suspicious_lines = []
                  keywords = ["key", "secret", "token", "password", "auth", "credential", "private"]
                  
                  for line in content.split('\n'):
                      if any(kw in line.lower() for kw in keywords):
                          suspicious_lines.append(line)
                  
                  if not suspicious_lines or len(suspicious_lines) < 2:
                      return None
                  
                  sample = '\n'.join(suspicious_lines[:30])
                  
                  prompt = f"""Security analysis of JavaScript code. Identify ONLY real security issues.

          File: {os.path.basename(url)}
          Lines to analyze:
          ```javascript
          {sample[:2000]}
          ```

          CRITICAL: Only flag if you see ACTUAL credentials with real values.
          
          IGNORE these (not vulnerabilities):
          - Variable names without values (e.g., "const apiKey = '';")
          - Placeholders like "YOUR_API_KEY", "INSERT_KEY_HERE"
          - Configuration templates
          - Comments or documentation
          - Example code
          
          If you find a REAL issue, return:
          {{
            "has_vulnerability": true,
            "type": "specific_type",
            "severity": "CRITICAL|HIGH|MEDIUM",
            "description": "What was found",
            "evidence": "Exact line with issue",
            "confidence": "high|medium",
            "recommendation": "Specific action to take"
          }}
          
          If no REAL issues: {{"has_vulnerability": false}}
          
          Return ONLY valid JSON, no markdown."""
                  
                  try:
                      response = client.chat.completions.create(
                          model="llama-3.3-70b-versatile",
                          messages=[{"role": "user", "content": prompt}],
                          max_tokens=600,
                          temperature=0.2
                      )
                      
                      content = response.choices[0].message.content.strip()
                      content = content.replace("```json", "").replace("```", "").strip()
                      
                      result = json.loads(content)
                      
                      if result.get("has_vulnerability") and result.get("confidence") == "high":
                          return {
                              "type": result.get("type", "unknown"),
                              "severity": result.get("severity", "MEDIUM"),
                              "risk": "Detected by LLM analysis",
                              "url": url,
                              "description": result.get("description", "")[:300],
                              "evidence": result.get("evidence", "")[:300],
                              "confidence": "llm_verified",
                              "recommendation": result.get("recommendation", "Review and remediate")
                          }
                  
                  except Exception as e:
                      print(f"  LLM error: {e}", file=sys.stderr)
                  
                  return None
              
              async def analyze_file(self, url: str, content: str) -> List[Dict]:
                  """Comprehensive file analysis"""
                  self.stats["total_files"] += 1
                  
                  # Check if library
                  if self.is_library(url):
                      self.stats["skipped_libraries"] += 1
                      return []
                  
                  # Check if duplicate
                  if self.is_duplicate(content):
                      self.stats["skipped_duplicates"] += 1
                      return []
                  
                  self.stats["analyzed"] += 1
                  findings = []
                  
                  # Pattern scan (fast)
                  pattern_findings = self.pattern_scan(content, url)
                  findings.extend(pattern_findings)
                  
                  # LLM analysis (deeper, slower)
                  if client and len(content) > 500:
                      llm_finding = await self.llm_analyze(content, url)
                      if llm_finding:
                          findings.append(llm_finding)
                  
                  if findings:
                      self.stats["findings"] += len(findings)
                  
                  return findings
          
          
          async def download_js(url: str, timeout: int = 15) -> Optional[str]:
              """Download JS with better error handling"""
              try:
                  import subprocess
                  result = subprocess.run(
                      ["curl", "-sL", "-A", "Mozilla/5.0", "--max-time", str(timeout), url],
                      capture_output=True,
                      timeout=timeout + 2
                  )
                  
                  if result.returncode == 0:
                      content = result.stdout.decode('utf-8', errors='ignore')
                      if len(content) > 200:  # Minimum size
                          return content
              except Exception:
                  pass
              
              return None
          
          
          async def main():
              if len(sys.argv) < 2:
                  print("Usage: python production_js_scanner.py <js_urls.txt>", file=sys.stderr)
                  sys.exit(1)
              
              js_list = sys.argv[1]
              
              if not os.path.exists(js_list):
                  print(f"‚ùå Not found: {js_list}", file=sys.stderr)
                  sys.exit(1)
              
              with open(js_list, 'r') as f:
                  urls = [line.strip() for line in f if line.strip()]
              
              if not urls:
                  print(json.dumps({"findings": [], "stats": {}}))
                  return
              
              analyzer = JavaScriptAnalyzer()
              
              print(f"üß† Production Scanner", file=sys.stderr)
              print(f"   URLs: {len(urls)}", file=sys.stderr)
              print(f"   LLM: {'‚úÖ Active' if client else '‚ö†Ô∏è Pattern-only'}", file=sys.stderr)
              print("", file=sys.stderr)
              
              all_findings = []
              
              for i, url in enumerate(urls, 1):
                  filename = os.path.basename(urlparse(url).path) or "unknown.js"
                  print(f"[{i}/{len(urls)}] {filename[:50]}", file=sys.stderr)
                  
                  content = await download_js(url)
                  
                  if not content:
                      print(f"  ‚ö†Ô∏è Download failed", file=sys.stderr)
                      continue
                  
                  findings = await analyzer.analyze_file(url, content)
                  
                  if findings:
                      print(f"  üî• {len(findings)} finding(s)", file=sys.stderr)
                      all_findings.extend(findings)
                  else:
                      print(f"  ‚úì Clean", file=sys.stderr)
                  
                  # Rate limiting
                  await asyncio.sleep(0.5)
              
              # Sort by severity
              severity_order = {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3}
              all_findings.sort(key=lambda x: severity_order.get(x.get("severity", "LOW"), 4))
              
              # Output
              output = {
                  "findings": all_findings,
                  "stats": analyzer.stats
              }
              
              print(json.dumps(output, indent=2))
              
              # Save
              with open("scan_results.json", "w") as f:
                  json.dump(output, f, indent=2)
              
              print("", file=sys.stderr)
              print("üìä Statistics:", file=sys.stderr)
              print(f"   Total files: {analyzer.stats['total_files']}", file=sys.stderr)
              print(f"   Analyzed: {analyzer.stats['analyzed']}", file=sys.stderr)
              print(f"   Skipped (duplicates): {analyzer.stats['skipped_duplicates']}", file=sys.stderr)
              print(f"   Skipped (libraries): {analyzer.stats['skipped_libraries']}", file=sys.stderr)
              print(f"   üî• Findings: {analyzer.stats['findings']}", file=sys.stderr)
          
          
          if __name__ == "__main__":
              asyncio.run(main())
          PYTHON_SCRIPT
          
          chmod +x production_js_scanner.py

      - name: Run Production Scan
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          set -euo pipefail
          
          mkdir -p reports tmp stats
          
          domains_scanned=0
          js_analyzed=0
          total_findings=0
          critical_findings=0
          high_findings=0
          
          # Validate targets
          if [[ ! -f targets.txt ]] || [[ ! -s targets.txt ]]; then
            echo "example.com" > targets.txt
          fi
          
          # Select targets (increased to 6 for better coverage)
          grep -v '^#' targets.txt | grep -v '^$' | shuf -n 6 > tmp/selected.txt || echo "example.com" > tmp/selected.txt
          
          echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
          echo "üß† PRODUCTION JS SECURITY SCANNER"
          echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
          cat tmp/selected.txt | nl
          echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
          echo ""
          
          # Process domains
          while read -r domain; do
            [[ -z "$domain" ]] && continue
            domain=$(echo "$domain" | tr -d '[:space:]' | tr '[:upper:]' '[:lower:]')
            [[ -z "$domain" ]] && continue
            
            domains_scanned=$((domains_scanned + 1))
            
            echo ""
            echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
            echo "üîç [$domains_scanned] $domain"
            echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
            
            report="reports/${domain}_report.md"
            
            # JS Discovery (increased depth)
            echo "üì° Discovering JavaScript..."
            timeout 90s katana -u "https://$domain" -jc -d 3 -c 20 -silent > tmp/urls_${domain}.txt 2>/dev/null || touch tmp/urls_${domain}.txt
            
            if [[ -s tmp/urls_${domain}.txt ]]; then
              # Smart filtering
              grep -iE '\.js(\?|$)' tmp/urls_${domain}.txt | \
                grep -iv '\.json' | \
                sort -u | head -n 15 > tmp/js_${domain}.txt || true
              
              js_count=$(wc -l < tmp/js_${domain}.txt 2>/dev/null || echo "0")
              
              if [[ $js_count -gt 0 ]]; then
                echo "üß† Analyzing $js_count JavaScript files..."
                
                python3 production_js_scanner.py tmp/js_${domain}.txt > tmp/results_${domain}.json 2>&1 || true
                
                if [[ -f scan_results.json ]]; then
                  mv scan_results.json tmp/scan_${domain}.json
                  
                  # Parse results
                  finding_count=$(jq '.findings | length' tmp/scan_${domain}.json 2>/dev/null || echo "0")
                  critical=$(jq '[.findings[] | select(.severity=="CRITICAL")] | length' tmp/scan_${domain}.json 2>/dev/null || echo "0")
                  high=$(jq '[.findings[] | select(.severity=="HIGH")] | length' tmp/scan_${domain}.json 2>/dev/null || echo "0")
                  analyzed=$(jq '.stats.analyzed' tmp/scan_${domain}.json 2>/dev/null || echo "0")
                  
                  total_findings=$((total_findings + finding_count))
                  critical_findings=$((critical_findings + critical))
                  high_findings=$((high_findings + high))
                  js_analyzed=$((js_analyzed + analyzed))
                  
                  # Generate report
                  cat > "$report" << EOF
          # üß† JS Security Analysis: $domain
          
          **Scan Date:** $(date '+%Y-%m-%d %H:%M UTC')  
          **Run:** #${{ github.run_number }}  
          **Intelligence:** ${GROQ_API_KEY:+Groq LLM Active}${GROQ_API_KEY:-Pattern-Only Mode}
          
          ---
          
          ## üìä Scan Statistics
          
          | Metric | Value |
          |--------|------:|
          | JS Files Discovered | $js_count |
          | Files Analyzed | $analyzed |
          | Total Findings | **$finding_count** |
          | Critical Issues | **$critical** |
          | High Severity | **$high** |
          
          EOF
                  
                  if [[ $finding_count -gt 0 ]]; then
                    echo "" >> "$report"
                    echo "## üö® Security Findings" >> "$report"
                    echo "" >> "$report"
                    
                    # Group by severity
                    for severity in CRITICAL HIGH MEDIUM; do
                      count=$(jq "[.findings[] | select(.severity==\"$severity\")] | length" tmp/scan_${domain}.json 2>/dev/null || echo "0")
                      if [[ $count -gt 0 ]]; then
                        echo "### ${severity} Severity ($count)" >> "$report"
                        echo "" >> "$report"
                        
                        jq -r ".findings[] | select(.severity==\"$severity\") | \"
          #### \(.type | gsub(\"_\"; \" \") | ascii_upcase)
          
          **Severity:** \(.severity)  
          **Risk:** \(.risk)  
          **File:** \`\(.url)\`  
          \(if .line then \"**Line:** ~\(.line)\" else \"\" end)
          **Confidence:** \(.confidence)
          
          **Evidence:**
          \`\`\`javascript
          \(.evidence // .context)
          \`\`\`
          
          **‚ö° Action Required:**
          > \(.recommendation)
          
          ---
          \"" tmp/scan_${domain}.json >> "$report" 2>/dev/null
                      fi
                    done
                  else
                    echo "" >> "$report"
                    echo "## ‚úÖ No Security Issues Detected" >> "$report"
                    echo "" >> "$report"
                    echo "All analyzed JavaScript files passed security checks." >> "$report"
                  fi
                  
                  echo "‚úÖ Findings: $finding_count ($critical critical, $high high)"
                else
                  echo "‚ö†Ô∏è Scanner failed"
                fi
              else
                echo "‚ö†Ô∏è No JavaScript found"
              fi
            else
              echo "‚ö†Ô∏è Discovery failed"
            fi
            
            sleep 1
            
          done < tmp/selected.txt
          
          echo ""
          echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
          echo "üìä SCAN COMPLETE"
          echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
          echo "Domains: $domains_scanned"
          echo "JS Files: $js_analyzed"
          echo "Total Findings: $total_findings"
          echo "  Critical: $critical_findings"
          echo "  High: $high_findings"
          echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
          
          # Save stats for trending
          cat > stats/scan_${{ github.run_number }}.json << STATS_EOF
          {
            "run": ${{ github.run_number }},
            "date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "domains": $domains_scanned,
            "js_files": $js_analyzed,
            "findings": {
              "total": $total_findings,
              "critical": $critical_findings,
              "high": $high_findings
            }
          }
          STATS_EOF
          
          # Export
          echo "DOMAINS_SCANNED=$domains_scanned" >> $GITHUB_ENV
          echo "JS_ANALYZED=$js_analyzed" >> $GITHUB_ENV
          echo "TOTAL_FINDINGS=$total_findings" >> $GITHUB_ENV
          echo "CRITICAL_FINDINGS=$critical_findings" >> $GITHUB_ENV
          echo "HIGH_FINDINGS=$high_findings" >> $GITHUB_ENV
          
          [[ $total_findings -gt 0 ]] && echo "HAS_FINDINGS=true" >> $GITHUB_ENV || echo "HAS_FINDINGS=false" >> $GITHUB_ENV
          [[ $critical_findings -gt 0 ]] && echo "HAS_CRITICAL=true" >> $GITHUB_ENV || echo "HAS_CRITICAL=false" >> $GITHUB_ENV

      - name: Generate Executive Summary
        if: always()
        run: |
          mkdir -p reports
          
          cat > reports/EXECUTIVE_SUMMARY.md << 'SUMMARY_EOF'
          # üß† JS Security Scanner - Executive Summary
          
          **Scan Date:** $(date '+%Y-%m-%d %H:%M UTC')  
          **Run:** #${{ github.run_number }}  
          **Intelligence:** ${GROQ_API_KEY:+‚úÖ AI-Powered}${GROQ_API_KEY:-‚ö†Ô∏è Pattern-Only}
          
          ---
          
          ## üìä Key Metrics
          
          | Metric | Value | Status |
          |--------|------:|:------:|
          | Domains Scanned | ${DOMAINS_SCANNED:-0} | ‚úÖ |
          | JS Files Analyzed | ${JS_ANALYZED:-0} | ‚úÖ |
          | **Total Findings** | **${TOTAL_FINDINGS:-0}** | $(if [[ "${TOTAL_FINDINGS:-0}" -gt 0 ]]; then echo "‚ö†Ô∏è"; else echo "‚úÖ"; fi) |
          | Critical Issues | ${CRITICAL_FINDINGS:-0} | $(if [[ "${CRITICAL_FINDINGS:-0}" -gt 0 ]]; then echo "üö®"; else echo "‚úÖ"; fi) |
          | High Severity | ${HIGH_FINDINGS:-0} | $(if [[ "${HIGH_FINDINGS:-0}" -gt 0 ]]; then echo "‚ö†Ô∏è"; else echo "‚úÖ"; fi) |
          
          ## üéØ Scanned Domains
          
          $(cat tmp/selected.txt 2>/dev/null | nl -w2 -s'. ' || echo "None")
          
          ## üîç Assessment
          
          $(if [[ "${CRITICAL_FINDINGS:-0}" -gt 0 ]]; then
            echo "### üö® CRITICAL ALERT"
            echo ""
            echo "${CRITICAL_FINDINGS} critical security issue(s) detected requiring **immediate action**."
            echo ""
            echo "**Recommended Actions:**"
            echo "1. Review detailed reports immediately"
            echo "2. Rotate any exposed credentials"
            echo "3. Check access logs for unauthorized use"
            echo "4. Implement remediation steps"
          elif [[ "${HIGH_FINDINGS:-0}" -gt 0 ]]; then
            echo "### ‚ö†Ô∏è HIGH PRIORITY"
            echo ""
            echo "${HIGH_FINDINGS} high-severity issue(s) detected requiring **prompt attention**."
            echo ""
            echo "**Recommended Actions:**"
            echo "1. Review findings within 24 hours"
            echo "2. Assess impact and exposure"
            echo "3. Plan remediation timeline"
          elif [[ "${TOTAL_FINDINGS:-0}" -gt 0 ]]; then
            echo "### ‚ÑπÔ∏è FINDINGS DETECTED"
            echo ""
            echo "${TOTAL_FINDINGS} medium/low severity issue(s) detected."
            echo ""
            echo "**Recommended Actions:**"
            echo "1. Review at next scheduled security review"
            echo "2. Add to remediation backlog"
          else
            echo "### ‚úÖ ALL CLEAR"
            echo ""
            echo "No security issues detected in analyzed JavaScript files."
            echo ""
            echo "**Next Steps:**"
            echo "- Continue regular scanning"
            echo "- Monitor for new deployments"
          fi)
          
          ## üìù Detailed Reports
          
          $(ls reports/*_report.md 2>/dev/null | sed 's/reports\//- /' || echo "- No domain reports")
          
          ---
          
          **Repository:** ${{ github.repository }}  
          **Workflow:** https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
          SUMMARY_EOF

      - name: Upload Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-${{ github.run_number }}
          path: |
            reports/
            stats/
            tmp/*.json
          retention-days: 30

      - name: Email Security Report
        if: always() && env.DOMAINS_SCANNED != '0'
        continue-on-error: true
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "${{ env.HAS_CRITICAL == 'true' && 'üö® CRITICAL' || env.HAS_FINDINGS == 'true' && '‚ö†Ô∏è FINDINGS' || '‚úÖ CLEAN' }} | JS Security Scan #${{ github.run_number }}"
          to: ${{ secrets.EMAIL_USERNAME }}
          from: Security Scanner <security@scanner.local>
          body: |
            üß† PRODUCTION JS SECURITY SCAN REPORT
            ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
            
            üìÖ $(date '+%Y-%m-%d %H:%M UTC')
            üîÑ Run #${{ github.run_number }}
            
            üìä METRICS
            ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
            ‚Ä¢ Domains:         ${{ env.DOMAINS_SCANNED }}
            ‚Ä¢ JS Files:        ${{ env.JS_ANALYZED }}
            ‚Ä¢ Total Findings:  ${{ env.TOTAL_FINDINGS }}
            ‚Ä¢ üî• Critical:     ${{ env.CRITICAL_FINDINGS }}
            ‚Ä¢ ‚ö†Ô∏è  High:        ${{ env.HIGH_FINDINGS }}
            
            ${{ env.HAS_CRITICAL == 'true' && 'üö®üö®üö® CRITICAL ISSUES - IMMEDIATE ACTION REQUIRED üö®üö®üö®' || env.HAS_FINDINGS == 'true' && '‚ö†Ô∏è SECURITY ISSUES DETECTED - REVIEW REQUIRED' || '‚úÖ NO ISSUES DETECTED' }}
            
            üìé ATTACHMENTS
            ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
            ‚Ä¢ EXECUTIVE_SUMMARY.md - Overview
            ‚Ä¢ *_report.md - Detailed findings per domain
            
            üîó Full results: 
            https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
            
            ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
            Powered by AI + Pattern Analysis | ${{ github.repository }}
          attachments: reports/*
          priority: ${{ env.HAS_CRITICAL == 'true' && 'high' || 'normal' }}

      - name: Cleanup
        if: always()
        run: rm -rf tmp/*.txt tmp/*.js 2>/dev/null || true
