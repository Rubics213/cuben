name: Production JS Security Scanner

on:
  push:
    branches: [main, master]
    paths:
      - 'targets.txt'
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'

permissions:
  contents: write
  actions: read

jobs:
  intelligent-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup Directories
        run: |
          mkdir -p reports tmp stats
          echo "âœ… Workspace ready"

      - name: Cache Tools
        id: cache-tools
        uses: actions/cache@v4
        with:
          path: ~/go/bin
          key: ${{ runner.os }}-tools-v5

      - name: Install Dependencies
        run: |
          echo "ðŸ“¦ Installing packages..."
          pip install --no-cache-dir groq aiohttp requests || pip install --break-system-packages groq aiohttp requests
          if [[ ! -f ~/go/bin/katana ]]; then
            go install github.com/projectdiscovery/katana/cmd/katana@latest
          fi
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
          echo "âœ… Ready"

      - name: Create Production Scanner
        run: |
          cat > production_js_scanner.py << 'PYTHON_SCRIPT'
          import os, sys, json, asyncio, re, hashlib
          from typing import List, Dict, Optional, Set
          from urllib.parse import urlparse
          try:
              from groq import Groq
              GROQ_AVAILABLE = True
          except ImportError:
              GROQ_AVAILABLE = False

          GROQ_API_KEY = os.getenv("GROQ_API_KEY")
          client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY and GROQ_AVAILABLE else None

          PATTERNS = {
              "private_key": {"regex": r'-----BEGIN (RSA |EC |DSA |OPENSSH )?PRIVATE KEY-----', "severity": "CRITICAL", "risk": "Full system compromise"},
              "aws_key": {"regex": r'(?i)(AKIA|ASIA)[A-Z0-9]{16}', "severity": "CRITICAL", "risk": "AWS account takeover"},
              "jwt_token": {"regex": r'eyJ[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}', "severity": "HIGH", "risk": "Session hijacking"},
              "api_key": {"regex": r'(?i)(api[_-]?key|apikey)\s*[:=]\s*["\']([a-zA-Z0-9_\-]{20,})["\']', "severity": "HIGH", "risk": "Unauthorized API access"},
              "github_token": {"regex": r'gh[pousr]_[A-Za-z0-9_]{36,}', "severity": "CRITICAL", "risk": "Repository access"},
              "database_url": {"regex": r'(?i)(mongodb|mysql|postgres|redis)://[^\s\'"]+', "severity": "CRITICAL", "risk": "Database access"}
          }

          class JavaScriptAnalyzer:
              def __init__(self):
                  self.seen_hashes = set()
                  self.stats = {"total_files": 0, "skipped_duplicates": 0, "skipped_libraries": 0, "analyzed": 0, "findings": 0}

              async def analyze_file(self, url: str, content: str) -> List[Dict]:
                  self.stats["total_files"] += 1
                  h = hashlib.md5(content.encode()).hexdigest()
                  if h in self.seen_hashes:
                      self.stats["skipped_duplicates"] += 1
                      return []
                  self.seen_hashes.add(h)
                  self.stats["analyzed"] += 1
                  findings = []
                  for name, p in PATTERNS.items():
                      for m in re.finditer(p["regex"], content):
                          findings.append({"type": name, "severity": p["severity"], "url": url, "evidence": content[max(0, m.start()-50):min(len(content), m.end()+50)].strip(), "risk": p["risk"], "confidence": "pattern_match", "recommendation": "Rotate immediately."})
                  self.stats["findings"] += len(findings)
                  return findings

          async def main():
              js_list = sys.argv[1]
              with open(js_list, 'r') as f: urls = [l.strip() for l in f if l.strip()]
              analyzer = JavaScriptAnalyzer()
              all_findings = []
              import requests
              for url in urls:
                  try:
                      r = requests.get(url, timeout=10)
                      if r.status_code == 200:
                          f = await analyzer.analyze_file(url, r.text)
                          all_findings.extend(f)
                  except: continue
              output = {"findings": all_findings, "stats": analyzer.stats}
              print(json.dumps(output, indent=2))
              with open("scan_results.json", "w") as f: json.dump(output, f)

          if __name__ == "__main__": asyncio.run(main())
          PYTHON_SCRIPT
          chmod +x production_js_scanner.py

      - name: Run Production Scan
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          set -euo pipefail
          mkdir -p reports tmp stats
          domains_scanned=0
          js_analyzed=0
          total_findings=0
          critical_findings=0
          high_findings=0

          # Fix Targets & Shuf Logic (Point 2)
          grep -v '^#' targets.txt | grep -v '^$' | shuf -n 6 > tmp/selected.txt

          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "ðŸ§  PRODUCTION JS SECURITY SCANNER"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          cat tmp/selected.txt | nl
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

          while read -r domain; do
            [[ -z "$domain" ]] && continue
            domain=$(echo "$domain" | tr -d '[:space:]' | tr '[:upper:]' '[:lower:]')
            domains_scanned=$((domains_scanned + 1))
            
            echo ""
            echo "ðŸ“¡ DISCOVERING: $domain"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            
            # JS Discovery (Restored Satellite Headers)
            timeout 90s katana -u "https://$domain" -jc -d 3 -c 20 -fs rdn -silent > tmp/urls_${domain}.txt 2>/dev/null || touch tmp/urls_${domain}.txt
            
            if [[ -s tmp/urls_${domain}.txt ]]; then
              # Fix Broken Pipe: output to file first
              grep -iE '\.js(\?|$)' tmp/urls_${domain}.txt | grep -iv '\.json' | sort -u > tmp/js_sorted_${domain}.txt || true
              head -n 15 tmp/js_sorted_${domain}.txt > tmp/js_${domain}.txt || true
              
              js_count=$(wc -l < tmp/js_${domain}.txt)
              if [[ $js_count -gt 0 ]]; then
                python3 production_js_scanner.py tmp/js_${domain}.txt > /dev/null 2>&1 || true
                
                if [[ -f scan_results.json ]]; then
                  mv scan_results.json tmp/scan_${domain}.json
                  finding_count=$(jq '.findings | length' tmp/scan_${domain}.json)
                  crit=$(jq '[.findings[] | select(.severity=="CRITICAL")] | length' tmp/scan_${domain}.json)
                  hgh=$(jq '[.findings[] | select(.severity=="HIGH")] | length' tmp/scan_${domain}.json)
                  anlz=$(jq '.stats.analyzed' tmp/scan_${domain}.json)
                  
                  total_findings=$((total_findings + finding_count))
                  critical_findings=$((critical_findings + crit))
                  high_findings=$((high_findings + hgh))
                  js_analyzed=$((js_analyzed + anlz))

                  # Generate Domain Markdown Report
                  cat > "reports/${domain}_report.md" << EOF
          # ðŸ§  JS Security Analysis: $domain
          **Files Analyzed:** $anlz | **Findings:** $finding_count
          ---
          $(jq -r '.findings[] | "### \(.type)\n- **Severity:** \(.severity)\n- **Evidence:** \`\(.evidence)\`\n"' tmp/scan_${domain}.json)
          EOF
                  echo "âœ… Analyzed $anlz files. Findings: $finding_count"
                fi
              fi
            fi
          done < tmp/selected.txt

          # Export Env Vars for next steps
          echo "DOMAINS_SCANNED=$domains_scanned" >> $GITHUB_ENV
          echo "JS_ANALYZED=$js_analyzed" >> $GITHUB_ENV
          echo "TOTAL_FINDINGS=$total_findings" >> $GITHUB_ENV
          echo "CRITICAL_FINDINGS=$critical_findings" >> $GITHUB_ENV
          echo "HIGH_FINDINGS=$high_findings" >> $GITHUB_ENV
          [[ $total_findings -gt 0 ]] && echo "HAS_FINDINGS=true" >> $GITHUB_ENV || echo "HAS_FINDINGS=false" >> $GITHUB_ENV
          [[ $critical_findings -gt 0 ]] && echo "HAS_CRITICAL=true" >> $GITHUB_ENV || echo "HAS_CRITICAL=false" >> $GITHUB_ENV

      - name: Generate Executive Summary
        if: always()
        run: |
          cat > reports/EXECUTIVE_SUMMARY.md << EOF
          # ðŸ§  Executive Summary Run #${{ github.run_number }}
          - Domains Scanned: $DOMAINS_SCANNED
          - JS Files Analyzed: $JS_ANALYZED
          - Critical Findings: $CRITICAL_FINDINGS
          - High Findings: $HIGH_FINDINGS
          EOF

      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-scan-${{ github.run_number }}
          path: reports/
          retention-days: 7

      - name: Email Security Report
        if: always()
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "${{ env.HAS_CRITICAL == 'true' && 'ðŸš¨ CRITICAL' || 'âœ… JS SCAN' }} | #${{ github.run_number }}"
          to: ${{ secrets.EMAIL_USERNAME }}
          from: Security Scanner
          body: |
            ðŸ“Š SCAN SUMMARY
            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            â€¢ Domains Scanned: ${{ env.DOMAINS_SCANNED }}
            â€¢ JS Analyzed:     ${{ env.JS_ANALYZED }}
            â€¢ Critical:        ${{ env.CRITICAL_FINDINGS }}
            â€¢ High:            ${{ env.HIGH_FINDINGS }}
            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            Check GitHub Artifacts for detailed reports.
