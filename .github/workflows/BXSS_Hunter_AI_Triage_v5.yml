name: BXSS Hunter with AI Triage

on:
  push:
    branches: [main, master]
    paths:
      - 'targets.txt'
  workflow_dispatch:
  schedule:
    - cron: '0 4 * * *'

permissions:
  contents: write
  actions: read

jobs:
  bxss_scan:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Python Dependencies
        run: |
          pip install google-generativeai requests

      - name: Install Security Tools
        run: |
          go install github.com/projectdiscovery/katana/cmd/katana@latest
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          go install github.com/hahwul/dalfox/v2@latest
          go install github.com/lc/gau/v2/cmd/gau@latest
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH

      - name: Run BXSS Scan
        env:
          EMAIL_USERNAME: ${{ secrets.EMAIL_USERNAME }}
        run: |
          mkdir -p bxss_reports tmp
          
          # 1. Target Selection
          if [[ ! -f targets.txt ]] || [[ ! -s targets.txt ]]; then
            echo "targets.txt is missing or empty"
            exit 0
          fi
          
          shuf -n 3 targets.txt > tmp/selected_targets.txt
          
          domains_scanned=0
          vulnerable_urls=0
          
          while read -r domain; do
            [[ -z "$domain" || "$domain" =~ ^# ]] && continue
            echo "ðŸ”¥ Scanning $domain for Blind XSS..."
            
            report="bxss_reports/BXSS_${domain}.md"
            cat > "$report" << EOF
          # BXSS Report: $domain
          **Date:** $(date)
          
          ---
          EOF
            
            # 2. URL Collection (Passive + Active)
            echo "  --> Collecting URLs..."
            gau "$domain" --threads 5 > tmp/urls_gau.txt 2>/dev/null || true
            katana -u "https://$domain" -d 2 -jc -silent > tmp/urls_katana.txt 2>/dev/null || true
            
            cat tmp/urls_gau.txt tmp/urls_katana.txt | sort -u | grep "=" > tmp/params_${domain}.txt
            
            url_count=$(wc -l < tmp/params_${domain}.txt)
            echo "  --> Found $url_count parameter URLs."
            
            if [ "$url_count" -gt 0 ]; then
               # 3. Dalfox Blind Scan
               # Note: Using a dummy blind payload for detection simulation or configuration
               echo "  --> Running Dalfox..."
               dalfox file tmp/params_${domain}.txt \
                 --skip-bav \
                 --silence \
                 --no-color \
                 --format json \
                 -o tmp/dalfox_${domain}.json 2>/dev/null || true
               
               if [ -f tmp/dalfox_${domain}.json ] && [ -s tmp/dalfox_${domain}.json ]; then
                  findings=$(jq -r '.[].url' tmp/dalfox_${domain}.json 2>/dev/null | head -n 20)
                  if [ -n "$findings" ]; then
                     echo "### ðŸš¨ Potential XSS Found" >> "$report"
                     echo '```' >> "$report"
                     echo "$findings" >> "$report"
                     echo '```' >> "$report"
                     vulnerable_urls=$((vulnerable_urls + 1))
                  else
                     echo "*No verified XSS payloads triggered.*" >> "$report"
                  fi
               else
                  echo "*No verified XSS payloads triggered.*" >> "$report"
               fi
            else
               echo "*No parameters found to scan.*" >> "$report"
            fi
            
            domains_scanned=$((domains_scanned + 1))
            
          done < tmp/selected_targets.txt
          
          echo "DOMAINS_SCANNED=$domains_scanned" >> $GITHUB_ENV
          echo "VULNERABLE_URLS=$vulnerable_urls" >> $GITHUB_ENV

      - name: ðŸ§  AI Triage (XSS Validation)
        id: ai_triage
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          VULNERABLE_URLS: ${{ env.VULNERABLE_URLS }}
        run: |
          if [ "${VULNERABLE_URLS:-0}" -eq 0 ]; then
             echo "HIGH_PRIORITY_FINDINGS=0" >> $GITHUB_ENV
             exit 0
          fi
          
          cat > triage_xss.py << 'EOF'
          import os, glob, json
          import google.generativeai as genai
          
          api_key = os.environ.get("GEMINI_API_KEY")
          if not api_key: exit(0)
          
          genai.configure(api_key=api_key)
          model = genai.GenerativeModel('gemini-1.5-flash')
          
          reports = glob.glob("bxss_reports/BXSS_*.md")
          confirmed_count = 0
          
          for report in reports:
              with open(report, 'r') as f:
                  content = f.read()
              if "### ðŸš¨ Potential XSS Found" not in content: continue
              
              prompt = f"""
              Analyze these URLs flagged by an automated XSS scanner (Dalfox).
              Determine if the parameters look like legitimate reflection points or false positives (e.g., static assets, navigation params).
              
              REPORT CONTENT:
              {content}
              
              OUTPUT:
              For each URL, state CONFIRMED or FALSE POSITIVE with reasoning.
              """
              
              try:
                  response = model.generate_content(prompt)
                  with open(report, 'a') as f:
                      f.write("\n\n## ðŸ§  AI Triage Analysis\n" + response.text)
                  if "CONFIRMED" in response.text.upper():
                      confirmed_count += 1
              except: pass
          
          with open("confirmed_xss.txt", "w") as f: f.write(str(confirmed_count))
          EOF
          
          python3 triage_xss.py
          CONFIRMED=$(cat confirmed_xss.txt 2>/dev/null || echo 0)
          echo "HIGH_PRIORITY_FINDINGS=$CONFIRMED" >> $GITHUB_ENV

      - name: Generate Summary
        if: always()
        run: |
          cat > bxss_reports/SUMMARY.md << EOF
          # BXSS Hunter Summary
          **Date:** $(date)
          
          | Metric | Count |
          |--------|-------|
          | Domains Scanned | ${DOMAINS_SCANNED:-0} |
          | Potential XSS | ${VULNERABLE_URLS:-0} |
          | **AI Confirmed** | **${HIGH_PRIORITY_FINDINGS:-0}** |
          EOF

      - name: Save Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: bxss-results
          path: bxss_reports/

      - name: Commit Results to History
        if: always()
        run: |
          git config --global user.name "BXSS Bot"
          git config --global user.email "bxss@bot.local"
          git fetch origin recon-history 2>/dev/null || true
          git checkout recon-history 2>/dev/null || git checkout -b recon-history
          mkdir -p bxss_history/$(date +%Y-%m-%d) 2>/dev/null || true
          cp bxss_reports/* bxss_history/$(date +%Y-%m-%d)/ 2>/dev/null || true
          git add .
          git commit -m "BXSS Scan: $(date)" && git push origin recon-history || true
