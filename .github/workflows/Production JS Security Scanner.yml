name: Production JS Security Scanner

on:
  push:
    branches: [main, master]
    paths:
      - 'targets.txt'
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *'

permissions:
  contents: write
  actions: read

jobs:
  intelligent-scan:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Setup Directories
        run: |
          mkdir -p reports tmp stats
          echo "âœ… Workspace ready"

      - name: Cache Tools
        id: cache-tools
        uses: actions/cache@v4
        with:
          path: ~/go/bin
          key: ${{ runner.os }}-tools-v5

      - name: Install Dependencies
        run: |
          echo "ğŸ“¦ Installing packages..."
          pip install --no-cache-dir groq aiohttp requests || pip install --break-system-packages groq aiohttp requests
          
          if [[ ! -f ~/go/bin/katana ]]; then
            go install github.com/projectdiscovery/katana/cmd/katana@latest
          fi
          
          echo "$(go env GOPATH)/bin" >> $GITHUB_PATH
          echo "âœ… Ready"

      - name: Create Production Scanner
        run: |
          cat > production_js_scanner.py << 'PYTHON_SCRIPT'
          import os, sys, json, asyncio, re, hashlib
          from typing import List, Dict, Optional, Set
          from urllib.parse import urlparse
          
          try:
              from groq import Groq
              GROQ_AVAILABLE = True
          except ImportError:
              GROQ_AVAILABLE = False
          
          GROQ_API_KEY = os.getenv("GROQ_API_KEY")
          client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY and GROQ_AVAILABLE else None
          
          PATTERNS = {
              "private_key": {"regex": r'-----BEGIN (RSA |EC |DSA |OPENSSH )?PRIVATE KEY-----', "severity": "CRITICAL", "risk": "Full system compromise"},
              "aws_key": {"regex": r'(?i)(AKIA|ASIA)[A-Z0-9]{16}', "severity": "CRITICAL", "risk": "AWS account takeover"},
              "jwt_token": {"regex": r'eyJ[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}\.[A-Za-z0-9_-]{10,}', "severity": "HIGH", "risk": "Session hijacking"},
              "api_key": {"regex": r'(?i)(api[_-]?key|apikey)\s*[:=]\s*["\']([a-zA-Z0-9_\-]{20,})["\']', "severity": "HIGH", "risk": "Unauthorized API access"},
              "github_token": {"regex": r'gh[pousr]_[A-Za-z0-9_]{36,}', "severity": "CRITICAL", "risk": "Repository access"},
              "slack_token": {"regex": r'xox[baprs]-[0-9]{10,13}-[0-9]{10,13}-[a-zA-Z0-9]{24,}', "severity": "HIGH", "risk": "Workspace compromise"},
              "database_url": {"regex": r'(?i)(mongodb|mysql|postgres|redis)://[^\s\'"]+', "severity": "CRITICAL", "risk": "Database access"}
          }
          
          BOILERPLATE_INDICATORS = ["example", "demo", "test", "placeholder", "sample", "your_", "insert_", "xxx", "abc123"]
          LIBRARY_INDICATORS = ["jquery", "bootstrap", "react", "angular", "vue", "lodash", "webpack", "vendor", "min.js"]

          class JavaScriptAnalyzer:
              def __init__(self):
                  self.seen_hashes: Set[str] = set()
                  self.stats = {"total_files": 0, "skipped_duplicates": 0, "skipped_libraries": 0, "analyzed": 0, "findings": 0}
              
              def is_library(self, url: str) -> bool:
                  return any(lib in url.lower() for lib in LIBRARY_INDICATORS)
              
              def is_boilerplate(self, text: str) -> bool:
                  return any(bp in text.lower() for bp in BOILERPLATE_INDICATORS)
              
              def get_content_hash(self, content: str) -> str:
                  return hashlib.md5(content.encode()).hexdigest()

              async def llm_analyze(self, content: str, url: str) -> Optional[Dict]:
                  if not client: return None
                  sample = content[:2000]
                  prompt = f"Analyze JS for real secrets. URL: {url}\nCode: {sample}\nReturn ONLY JSON with keys has_vulnerability, type, severity, description, evidence, confidence."
                  try:
                      resp = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=[{"role": "user", "content": prompt}], temperature=0.1)
                      res = json.loads(resp.choices[0].message.content.strip().replace("```json", "").replace("```", ""))
                      return res if res.get("has_vulnerability") and res.get("confidence") == "high" else None
                  except: return None

              async def analyze_file(self, url: str, content: str) -> List[Dict]:
                  self.stats["total_files"] += 1
                  if self.is_library(url): self.stats["skipped_libraries"] += 1; return []
                  h = self.get_content_hash(content)
                  if h in self.seen_hashes: self.stats["skipped_duplicates"] += 1; return []
                  self.seen_hashes.add(h)
                  self.stats["analyzed"] += 1
                  findings = []
                  for name, p in PATTERNS.items():
                      for m in re.finditer(p["regex"], content):
                          ctx = content[max(0, m.start()-100):min(len(content), m.end()+100)]
                          if not self.is_boilerplate(ctx):
                              findings.append({"type": name, "severity": p["severity"], "url": url, "evidence": ctx.strip(), "risk": p["risk"]})
                  if not findings and client:
                      llm = await self.llm_analyze(content, url)
                      if llm: findings.append(llm)
                  return findings

          async def main():
              with open(sys.argv[1], 'r') as f: urls = [l.strip() for l in f if l.strip()]
              analyzer = JavaScriptAnalyzer()
              all_findings = []
              import requests
              for url in urls:
                  try:
                      r = requests.get(url, timeout=10)
                      if r.status_code == 200:
                          f = await analyzer.analyze_file(url, r.text)
                          all_findings.extend(f)
                  except: continue
              print(json.dumps({"findings": all_findings, "stats": analyzer.stats}))

          if __name__ == "__main__": asyncio.run(main())
          PYTHON_SCRIPT
          chmod +x production_js_scanner.py

      - name: Run Production Scan
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          set -euo pipefail
          domains_scanned=0
          js_analyzed=0
          total_findings=0
          critical_findings=0
          high_findings=0

          # Selection Fix: Ensure exactly 5 targets
          grep -v '^#' targets.txt | grep -v '^$' | shuf -n 5 > tmp/selected.txt

          while read -r domain; do
            [[ -z "$domain" ]] && continue
            domain=$(echo "$domain" | tr -d '[:space:]' | tr '[:upper:]' '[:lower:]')
            domains_scanned=$((domains_scanned + 1))
            
            # Discovery Fix: added -fs rdn to prevent scope crawling leakage
            timeout 90s katana -u "https://$domain" -jc -d 3 -c 20 -fs rdn -silent > tmp/urls_${domain}.txt 2>/dev/null || touch tmp/urls_${domain}.txt
            
            if [[ -s tmp/urls_${domain}.txt ]]; then
              grep -iE '\.js(\?|$)' tmp/urls_${domain}.txt | grep -iv '\.json' | sort -u | head -n 15 > tmp/js_${domain}.txt || true
              if [[ -s tmp/js_${domain}.txt ]]; then
                python3 production_js_scanner.py tmp/js_${domain}.txt > tmp/results_${domain}.json 2>/dev/null
                
                finding_count=$(jq '.findings | length' tmp/results_${domain}.json 2>/dev/null || echo "0")
                critical=$(jq '[.findings[] | select(.severity=="CRITICAL")] | length' tmp/results_${domain}.json 2>/dev/null || echo "0")
                high=$(jq '[.findings[] | select(.severity=="HIGH")] | length' tmp/results_${domain}.json 2>/dev/null || echo "0")
                analyzed=$(jq '.stats.analyzed' tmp/results_${domain}.json 2>/dev/null || echo "0")
                
                total_findings=$((total_findings + finding_count))
                critical_findings=$((critical_findings + critical))
                high_findings=$((high_findings + high))
                js_analyzed=$((js_analyzed + analyzed))

                # Simple report generation
                echo "### $domain" >> reports/EXECUTIVE_SUMMARY.md
                echo "- Files: $analyzed | Findings: $finding_count" >> reports/EXECUTIVE_SUMMARY.md
              fi
            fi
          done < tmp/selected.txt

          echo "DOMAINS_SCANNED=$domains_scanned" >> $GITHUB_ENV
          echo "JS_ANALYZED=$js_analyzed" >> $GITHUB_ENV
          echo "TOTAL_FINDINGS=$total_findings" >> $GITHUB_ENV
          echo "CRITICAL_FINDINGS=$critical_findings" >> $GITHUB_ENV
          echo "HIGH_FINDINGS=$high_findings" >> $GITHUB_ENV
          [[ $total_findings -gt 0 ]] && echo "HAS_FINDINGS=true" >> $GITHUB_ENV || echo "HAS_FINDINGS=false" >> $GITHUB_ENV
          [[ $critical_findings -gt 0 ]] && echo "HAS_CRITICAL=true" >> $GITHUB_ENV || echo "HAS_CRITICAL=false" >> $GITHUB_ENV

      - name: Email Security Report
        if: always() && env.DOMAINS_SCANNED != '0'
        continue-on-error: true
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 465
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: "${{ env.HAS_CRITICAL == 'true' && 'ğŸš¨ CRITICAL' || env.HAS_FINDINGS == 'true' && 'âš ï¸ FINDINGS' || 'âœ… CLEAN' }} | JS Security Scan #${{ github.run_number }}"
          to: ${{ secrets.EMAIL_USERNAME }}
          from: Security Scanner <security@scanner.local>
          body: |
            ğŸ§  PRODUCTION JS SECURITY SCAN REPORT
            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            ğŸ“… $(date '+%Y-%m-%d %H:%M UTC')
            ğŸ”„ Run #${{ github.run_number }}
            
            ğŸ“Š METRICS
            â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            â€¢ Domains:         ${{ env.DOMAINS_SCANNED }}
            â€¢ JS Files:        ${{ env.JS_ANALYZED }}
            â€¢ Total Findings:   ${{ env.TOTAL_FINDINGS }}
            â€¢ ğŸ”¥ Critical:       ${{ env.CRITICAL_FINDINGS }}
            â€¢ âš ï¸  High:           ${{ env.HIGH_FINDINGS }}
            
            ${{ env.HAS_CRITICAL == 'true' && 'ğŸš¨ğŸš¨ğŸš¨ CRITICAL ISSUES DETECTED ğŸš¨ğŸš¨ğŸš¨' || 'âœ… Scan Completed' }}
